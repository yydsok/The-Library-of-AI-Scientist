# Papers on: Reasoning

Total: 14 papers

- [RxnBench: A Multimodal Benchmark for Evaluating Large Language Models on Chemical Reaction Understanding from Scientific Literature](https://arxiv.org/abs/2512.23565)
    - Hanzheng Li, Xi Fang, Yixuan Li, Chaozheng Huang, Junjie Wang, Xi Wang, Hongzhe Bai, Bojun Hao, et al.
    - ğŸ›ï¸ Institutions: INSTITUTIONS_NEEDED (check paper for affiliations)
    - ğŸ“… Date: December 29, 2025
    - ğŸ“‘ Publisher: arXiv
    - ğŸ’» Topic: [Scientific Discovery]
    - ğŸ”‘ Key: [llm], [automation], [benchmark], [reasoning], [discovery]
    - ğŸ“– TLDR: The integration of Multimodal Large Language Models (MLLMs) into chemistry promises to revolutionize scientific discovery, yet their ability to comprehend the dense, graphical language of reactions within authentic literature remains underexplored. Here, we introduce RxnBench, a multi-tiered benchma

- [Evaluating Large Language Models in Scientific Discovery](https://arxiv.org/abs/2512.15567)
    - Zhangde Song, Jieyu Lu, Yuanqi Du, Botao Yu, Thomas M. Pruyn, Yue Huang, Kehan Guo, Xiuzhe Luo, et al.
    - ğŸ›ï¸ Institutions: INSTITUTIONS_NEEDED (check paper for affiliations)
    - ğŸ“… Date: December 17, 2025
    - ğŸ“‘ Publisher: arXiv
    - ğŸ’» Topic: [Hypothesis Generation]
    - ğŸ”‘ Key: [llm], [framework], [benchmark], [reasoning], [discovery]
    - ğŸ“– TLDR: Large language models (LLMs) are increasingly applied to scientific research, yet prevailing science benchmarks probe decontextualized knowledge and overlook the iterative reasoning, hypothesis generation, and observation interpretation that drive scientific discovery. We introduce a scenario-ground

- [Kosmos: An AI Scientist for Autonomous Discovery](https://arxiv.org/abs/2511.02824)
    - Ludovico Mitchener, Angela Yiu, Benjamin Chang, Mathieu Bourdenx, Tyler Nadolski, Arvis Sulovari, Eric C. Landsness, Daniel L. Barabasi, et al.
    - ğŸ›ï¸ Institutions: INSTITUTIONS_NEEDED (check paper for affiliations)
    - ğŸ“… Date: November 04, 2025
    - ğŸ“‘ Publisher: arXiv
    - ğŸ’» Topic: [AI Scientist]
    - ğŸ”‘ Key: [agent], [automation], [framework], [dataset], [reasoning]
    - ğŸ“– TLDR: Data-driven scientific discovery requires iterative cycles of literature search, hypothesis generation, and data analysis. Substantial progress has been made towards AI agents that can automate scientific research, but all such agents remain limited in the number of actions they can take before losi

- [SciGPT: A Large Language Model for Scientific Literature Understanding and Knowledge Discovery](https://arxiv.org/abs/2509.08032)
    - Fengyu She, Nan Wang, Hongfei Wu, Ziyi Wan, Jingmian Wang, Chang Wang
    - ğŸ›ï¸ Institutions: INSTITUTIONS_NEEDED (check paper for affiliations)
    - ğŸ“… Date: September 09, 2025
    - ğŸ“‘ Publisher: arXiv
    - ğŸ’» Topic: [Scientific Discovery]
    - ğŸ”‘ Key: [llm], [benchmark], [reasoning], [discovery], [experiment]
    - ğŸ“– TLDR: Scientific literature is growing exponentially, creating a critical bottleneck for researchers to efficiently synthesize knowledge. While general-purpose Large Language Models (LLMs) show potential in text processing, they often fail to capture scientific domain-specific nuances (e.g., technical jar

- [Can Large Language Models Adequately Perform Symbolic Reasoning Over Time Series?](https://arxiv.org/abs/2508.03963)
    - Zewen Liu, Juntong Ni, Xianfeng Tang, Max S. Y. Lau, Wenpeng Yin, Wei Jin
    - ğŸ›ï¸ Institutions: INSTITUTIONS_NEEDED (check paper for affiliations)
    - ğŸ“… Date: August 05, 2025
    - ğŸ“‘ Publisher: arXiv
    - ğŸ’» Topic: [Scientific Discovery]
    - ğŸ”‘ Key: [llm], [automation], [framework], [benchmark], [reasoning]
    - ğŸ“– TLDR: Uncovering hidden symbolic laws from time series data, as an aspiration dating back to Kepler's discovery of planetary motion, remains a core challenge in scientific discovery and artificial intelligence. While Large Language Models show promise in structured reasoning tasks, their ability to infer

- [ScienceMeter: Tracking Scientific Knowledge Updates in Language Models](https://arxiv.org/abs/2505.24302)
    - Yike Wang, Shangbin Feng, Yulia Tsvetkov, Hannaneh Hajishirzi
    - ğŸ›ï¸ Institutions: INSTITUTIONS_NEEDED (check paper for affiliations)
    - ğŸ“… Date: May 30, 2025
    - ğŸ“‘ Publisher: arXiv
    - ğŸ’» Topic: [Misc]
    - ğŸ”‘ Key: [llm], [framework], [dataset], [reasoning], [experiment]
    - ğŸ“– TLDR: Large Language Models (LLMs) are increasingly used to support scientific research, but their knowledge of scientific advancements can quickly become outdated. We introduce ScienceMeter, a new framework for evaluating scientific knowledge update methods over scientific knowledge spanning the past, pr

- [Are Large Language Models Reliable AI Scientists? Assessing Reverse-Engineering of Black-Box Systems](https://arxiv.org/abs/2505.17968)
    - Jiayi Geng, Howard Chen, Dilip Arumugam, Thomas L. Griffiths
    - ğŸ›ï¸ Institutions: INSTITUTIONS_NEEDED (check paper for affiliations)
    - ğŸ“… Date: May 23, 2025
    - ğŸ“‘ Publisher: arXiv
    - ğŸ’» Topic: [AI Scientist]
    - ğŸ”‘ Key: [llm], [automation], [framework], [reasoning], [discovery]
    - ğŸ“– TLDR: Using AI to create autonomous researchers has the potential to accelerate scientific discovery. A prerequisite for this vision is understanding how well an AI model can identify the underlying structure of a black-box system from its behavior.

- [Advancing the Scientific Method with Large Language Models: From Hypothesis to Discovery](https://arxiv.org/abs/2505.16477)
    - Yanbo Zhang, Sumeer A. Khan, Adnan Mahmud, Huck Yang, Alexander Lavin, Michael Levin, Jeremy Frey, Jared Dunnmon, et al.
    - ğŸ›ï¸ Institutions: INSTITUTIONS_NEEDED (check paper for affiliations)
    - ğŸ“… Date: May 22, 2025
    - ğŸ“‘ Publisher: arXiv
    - ğŸ’» Topic: [Data Analysis]
    - ğŸ”‘ Key: [llm], [benchmark], [survey], [reasoning], [discovery]
    - ğŸ“– TLDR: With recent Nobel Prizes recognising AI contributions to science, Large Language Models (LLMs) are transforming scientific research by enhancing productivity and reshaping the scientific method. LLMs are now involved in experimental design, data analysis, and workflows, particularly in chemistry and

- [Toward Reliable Scientific Hypothesis Generation: Evaluating Truthfulness and Hallucination in Large Language Models](https://arxiv.org/abs/2505.14599)
    - Guangzhi Xiong, Eric Xie, Corey Williams, Myles Kim, Amir Hassan Shariatmadari, Sikun Guo, Stefan Bekiranov, Aidong Zhang
    - ğŸ›ï¸ Institutions: INSTITUTIONS_NEEDED (check paper for affiliations)
    - ğŸ“… Date: May 20, 2025
    - ğŸ“‘ Publisher: arXiv
    - ğŸ’» Topic: [Hypothesis Generation]
    - ğŸ”‘ Key: [llm], [framework], [benchmark], [reasoning], [discovery]
    - ğŸ“– TLDR: Large language models (LLMs) have shown significant potential in scientific disciplines such as biomedicine, particularly in hypothesis generation, where they can analyze vast literature, identify patterns, and suggest research directions. However, a key challenge lies in evaluating the truthfulness

- [LLM-SRBench: A New Benchmark for Scientific Equation Discovery with Large Language Models](https://arxiv.org/abs/2504.10415)
    - Parshin Shojaee, Ngoc-Hieu Nguyen, Kazem Meidani, Amir Barati Farimani, Khoa D Doan, Chandan K Reddy
    - ğŸ›ï¸ Institutions: INSTITUTIONS_NEEDED (check paper for affiliations)
    - ğŸ“… Date: April 14, 2025
    - ğŸ“‘ Publisher: arXiv
    - ğŸ’» Topic: [Hypothesis Generation]
    - ğŸ”‘ Key: [llm], [framework], [benchmark], [reasoning], [discovery]
    - ğŸ“– TLDR: Scientific equation discovery is a fundamental task in the history of scientific progress, enabling the derivation of laws governing natural phenomena. Recently, Large Language Models (LLMs) have gained interest for this task due to their potential to leverage embedded scientific knowledge for hypot

- [Exploiting Edited Large Language Models as General Scientific Optimizers](https://arxiv.org/abs/2503.09620)
    - Qitan Lv, Tianyu Liu, Hong Wang
    - ğŸ›ï¸ Institutions: INSTITUTIONS_NEEDED (check paper for affiliations)
    - ğŸ“… Date: March 08, 2025
    - ğŸ“‘ Publisher: arXiv
    - ğŸ’» Topic: [Misc]
    - ğŸ”‘ Key: [llm], [reasoning], [experiment]
    - ğŸ“– TLDR: Large language models (LLMs) have been widely adopted in mathematical optimization in scientific scenarios for their extensive knowledge and advanced reasoning capabilities. Existing methods mainly focus on utilizing LLMs to solve optimization problems in a prompt-based manner, which takes observati

- [Auto-Bench: An Automated Benchmark for Scientific Discovery in LLMs](https://arxiv.org/abs/2502.15224)
    - Tingting Chen, Srinivas Anumasa, Beibei Lin, Vedant Shah, Anirudh Goyal, Dianbo Liu
    - ğŸ›ï¸ Institutions: INSTITUTIONS_NEEDED (check paper for affiliations)
    - ğŸ“… Date: February 21, 2025
    - ğŸ“‘ Publisher: arXiv
    - ğŸ’» Topic: [AI Scientist]
    - ğŸ”‘ Key: [llm], [agent], [automation], [benchmark], [reasoning]
    - ğŸ“– TLDR: Given the remarkable performance of Large Language Models (LLMs), an important question arises: Can LLMs conduct human-like scientific research and discover new knowledge, and act as an AI scientist? Scientific discovery is an iterative process that demands efficient knowledge updating and encoding.

- [Large Language Models Meet Graph Neural Networks for Text-Numeric Graph Reasoning](https://arxiv.org/abs/2501.16361)
    - Haoran Song, Jiarui Feng, Guangfu Li, Michael Province, Philip Payne, Yixin Chen, Fuhai Li
    - ğŸ›ï¸ Institutions: INSTITUTIONS_NEEDED (check paper for affiliations)
    - ğŸ“… Date: January 21, 2025
    - ğŸ“‘ Publisher: arXiv
    - ğŸ’» Topic: [Scientific Discovery]
    - ğŸ”‘ Key: [llm], [benchmark], [dataset], [reasoning], [discovery]
    - ğŸ“– TLDR: In real-world scientific discovery, human beings always make use of the accumulated prior knowledge with imagination pick select one or a few most promising hypotheses from large and noisy data analysis results. In this study, we introduce a new type of graph structure, the text-numeric graph (TNG),

- [Large Language Models for Scientific Synthesis, Inference and Explanation](https://arxiv.org/abs/2310.07984)
    - Yizhen Zheng, Huan Yee Koh, Jiaxin Ju, Anh T. N. Nguyen, Lauren T. May, Geoffrey I. Webb, Shirui Pan
    - ğŸ›ï¸ Institutions: INSTITUTIONS_NEEDED (check paper for affiliations)
    - ğŸ“… Date: October 12, 2023
    - ğŸ“‘ Publisher: arXiv
    - ğŸ’» Topic: [Scientific Discovery]
    - ğŸ”‘ Key: [llm], [framework], [benchmark], [dataset], [reasoning]
    - ğŸ“– TLDR: Large language models are a form of artificial intelligence systems whose primary knowledge consists of the statistical patterns, semantic relationships, and syntactical structures of language1. Despite their limited forms of "knowledge", these systems are adept at numerous complex tasks including c

